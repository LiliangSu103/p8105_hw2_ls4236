p8105_hw2_ls4236
================
Liliang Su
2025-09-23

## Problem 1

### `pols-month`

First of all, load the required dataset `pols-month` and clean it, and
tidy the data according to the first step.

``` r
pol_df =
  read_csv("./data/pols-month.csv", na = c("NA",".","")) |> 
  janitor::clean_names() |> 
  separate(
    mon,
    into = c("year", "month", "day"),
    sep = "-"
  ) |> 
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    day = as.integer(day)
  ) |> 
  mutate(
    month = case_match(
      month,
      1 ~ "Jan",
      2 ~ "Feb",
      3 ~ "Mar",
      4 ~ "Apr",
      5 ~ "May",
      6 ~ "Jun",
      7 ~ "Jul",
      8 ~ "Aug",
      9 ~ "Sep",
      10 ~ "Oct",
      11 ~ "Nov",
      12 ~ "Dec"
    ),
    month = str_to_lower(month)
  ) |> 
# create column president to represent presidential party
  mutate(
    president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem"
    )
  ) |> 
  select(-prez_gop,-prez_dem,-day)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### `snp`

Second of all, load the required dataset `snp` and clean it, and tidy
the data according to the second step.

``` r
snp_df =
  read_csv("./data/snp.csv", na = c("NA",".","")) |> 
  janitor::clean_names() |> 
  separate(
    date,
    into = c("month", "day", "year"),
    sep = "/"
  ) |> 
  mutate(
    year = as.integer(year),
# here we convert year into 4 digit value
    year = ifelse(year < 16, 2000 + year, 1900 + year),
    month = as.integer(month),
    day = as.integer(day)
  ) |> 
  arrange(year, month) |> 
  mutate(
    month = case_match(
      month,
      1 ~ "Jan",
      2 ~ "Feb",
      3 ~ "Mar",
      4 ~ "Apr",
      5 ~ "May",
      6 ~ "Jun",
      7 ~ "Jul",
      8 ~ "Aug",
      9 ~ "Sep",
      10 ~ "Oct",
      11 ~ "Nov",
      12 ~ "Dec"
    ),
    month = str_to_lower(month)
  ) |> 
  relocate(year, month) |> 
  select(-day)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### `unemployment`

Third of all, load the required dataset `unemployment` and clean it, and
tidy the data according to the third step.

``` r
une_df =
  read_csv("./data/unemployment.csv", na = c("NA",".","")) |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = jan:dec,
    names_to = "month",
    values_to = "unemp_rate"
  )
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### Merge

Lastly, merge them in the order of `pol`, `snp`, `une`.

``` r
merge_df =
  pol_df |> 
  left_join(snp_df, by = c("year", "month")) |> 
  left_join(une_df, by = c("year", "month"))
```

### Summary

Overall, the three datasets together cover a series of political and
economic indicators.

The `pols-month` dataset includes 822 observations of 9
dimentions(variables) tracking the number of national politicians
monthly by party affiliation, spanning from 1947 to 2015. The key
variables include presidential party, number of governors, senators, and
representatives of both parties. The `snp` dataset provide 787
observations of monthly S&P 500 closing values from 1950 to 2015, which
can be seen as an indicator of stock market performance. The
`unemployment` dataset contains 68 observations with monthly
unemployment rate spanning from 1948 to 2015.

After cleaning and merging, the resulting dataset combines these data
into a comprehensive dataset with 822 rows and 11 variables, from 1947
to 2015. Key integrated variables include presidential party affiliation
(converted to a single president variable), S&P 500 closing values
(close), unemployment rates (une_rate), and detailed counts of
politicians by party.

## Problem 2

### `Mr. Trash Wheel`

Firstly, tidy up `Mr. Trash Wheel` dataset, and add `group = Mr` column
for combining

``` r
mr_wheel = read_excel(
  "./data/MTL.xlsx", 
  sheet = "Mr. Trash Wheel", 
  range = "A2:N653"
  ) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    year = as.integer(year),
    group = "Mr"
  ) |> 
  relocate(group)
```

### `Professor Trash Wheel`

Tidy up `Professor Trash Wheel` dataset, and add `group = Prof` column
for combining.

``` r
prof_wheel = read_excel(
  "./data/MTL.xlsx",
  sheet = "Professor Trash Wheel",
  range = "A2:M120"
) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(
    group = "Prof"
  ) |> 
  relocate(group)
```

### `Gwynnda Trash Wheel`

Tidy up `Gwynnda Trash Wheel` dataset, and add `group = Gwyn` column for
combining.

``` r
gwyn_wheel = read_excel(
  "./data/MTL.xlsx",
  sheet = "Gwynnda Trash Wheel",
  range = "A2:L265"
) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(
    group = "Gwyn"
  ) |> 
  relocate(group)
```

### Merge

Then combine these datasets using `bind_rows` function, as they are
basically the same variables measured across different groups.

``` r
combined_wheel = bind_rows(mr_wheel, prof_wheel, gwyn_wheel)
```

### Summary

Overall, the combined Trash Wheel dataset contains 1032 observations of
trash collection events from Baltimore’s three water-wheels, with
Mr. Trash Wheel contributing the majority of records (651) since 2014,
followed by Gwynnda (263) since 2021 and Professor Trash Wheel (118)
since 2017.

Key variables include:

- trash weight, with mean 3.0382461 tons, ranges from 0.61 to 5.62tons
  per dumpster
- trash volume, with mean 15.0765504 cubic yards and statistical mode
  15, ranges from 5 to 20 cubic yards
- specific trash items like cigarette butts with an average of
  1.3295924^{4} per observation, and plastic bottles, which is up to
  9830 items

In addition, Professor Trash Wheel records a total of 246.74 tons of
trash during its operational period.

In June 2022, Gwynnda Trash Wheel records a total number of 1.812^{4}
cigarette butts.

## Problem 3

### `zip`

Firstly, import and clean the `Zip Codes` dataset.

``` r
zip = 
  read_csv(file = "./data/Zip Codes.csv", na = c("NA",".","")) |> 
  janitor::clean_names() |> 
# file_date is the same for every observations, so it is redundant
  select(-file_date) |> 
  mutate(
    county_code = as.integer(county_code),
    state_fips = as.integer(state_fips),
    county_fips = as.integer(county_fips),
    zip_code = as.integer(zip_code)
  ) |> 
  rename(county_zip = county) # rename to differentiate bewteen both datasets
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### `zillow`

Secondly, import and clean the `Zillow Rental Price` dataset.

``` r
zillow = 
  read_csv(file = "./data/Zillow Rental Price.csv", na = c("NA",".","")) |> 
  janitor::clean_names() |> 
  select(-region_type, -state, -state_name, -city, -metro) |> # state, state_name, region_type, metro, and city are redundant as they have the same value for every observations
  rename(zip_code = region_name, county_zillow = county_name, region_id_zillow = region_id) |> # rename to differentiate bewteen both datasets
  pivot_longer(
    cols = x2015_01_31:x2024_08_31,
    names_prefix = "x",
    names_to = "date",
    values_to = "zori"
  ) |> # tidy up the date and zori variables
  filter(!is.na(zori)) |>  # zori is the main variable of interest, hence any row without a value can’t contribute to the analysis
  separate(
    date,
    into = c("year", "month", "day"),
    sep = "_"
  ) |> 
  relocate(year, month, day) |> 
  mutate(
    region_id_zillow = as.integer(region_id_zillow),
    size_rank = as.integer(size_rank),
    zip_code = as.integer(zip_code),
    year = as.integer(year),
    month = as.integer(month),
    day = as.integer(day),
    county_zillow = str_remove_all(county_zillow, " County") # remove the character "county" for all observations in the column "county"
  )
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### Merge

Then merge two datasets using `left_join` function by `zip_code`, and I
will relocate and arrange it later.

``` r
combined_zillow = left_join(zillow, zip, by = "zip_code")
```

    ## Warning in left_join(zillow, zip, by = "zip_code"): Detected an unexpected many-to-many relationship between `x` and `y`.
    ## ℹ Row 2759 of `x` matches multiple rows in `y`.
    ## ℹ Row 256 of `y` matches multiple rows in `x`.
    ## ℹ If a many-to-many relationship is expected, set `relationship =
    ##   "many-to-many"` to silence this warning.

**Note**: The warning results from the fact that certain zip codes
appear more than once, which lead to the warning where some `x` (Row
4757) matches multiple rows in `y`. Let’s check it.

``` r
zip |> count(zip_code) |> filter(n>1) |> pull(zip_code)
```

    ## [1] 10463 11201

``` r
zip |> filter(zip_code == "10463")
```

    ## # A tibble: 2 × 6
    ##   county_zip state_fips county_code county_fips zip_code neighborhood           
    ##   <chr>           <int>       <int>       <int>    <int> <chr>                  
    ## 1 Bronx              36           5       36005    10463 Kingsbridge and Riverd…
    ## 2 New York           36          61       36061    10463 Kingsbridge and Riverd…

``` r
zip |> filter( zip_code == "11201")
```

    ## # A tibble: 2 × 6
    ##   county_zip state_fips county_code county_fips zip_code neighborhood      
    ##   <chr>           <int>       <int>       <int>    <int> <chr>             
    ## 1 Kings              36          47       36047    11201 Northwest Brooklyn
    ## 2 New York           36          61       36061    11201 Northwest Brooklyn

This is probably due to the fact that 11201 is mostly in Kings County
(Brooklyn), but part of it overlaps into New York County (Manhattan). So
after double checking, I decide to remove the rows where 11201
corresponds to Manhattan and 10463 corresponds to Manhattan.

``` r
zip = zip |> 
  filter(!(zip_code %in% c("10463", "11201") & county_zip == "New York"))
```

In addition, there is also some mismatches between `county_zillow` and
`county_zip`. After double checking, I decide to change the
corresponding `county_zip` into same values as `county_zillow`.

``` r
which(pull(combined_zillow, county_zillow) != pull(combined_zillow, county_zip))
```

    ##   [1] 2760 2762 2764 2766 2768 2770 2772 2774 2776 2778 2780 2782 2784 2786 2788
    ##  [16] 2790 2792 2794 2796 2798 2800 2802 2804 2806 2808 2810 2812 2814 2816 2818
    ##  [31] 2820 2822 2824 2826 2828 2830 2832 2834 2836 2838 2840 2842 2844 2846 2848
    ##  [46] 2850 2852 2854 2856 2858 2860 2862 2864 2866 2868 2870 2872 2874 2876 2878
    ##  [61] 2880 2882 2884 2886 2888 2890 2892 2894 2896 2898 2900 2902 2904 2906 2908
    ##  [76] 2910 2912 2914 2916 2918 2920 2922 2924 2926 2928 2930 2932 2934 2936 2938
    ##  [91] 2940 2942 2944 2946 2948 2950 2952 2954 2956 2958 2960 2962 2964 2966 2968
    ## [106] 2970 2972 2974 2976 2978 2980 3177 3179 3181 3183 3185 3187 3189 3191 3193
    ## [121] 3195 3197 3199 3201 3203 3205 3207 3209 3211 3213 3215 3217 3219 3221 3223
    ## [136] 3225 3227 3229 3231 3233 3235 3237 3239 3241 3243 3245 3247 3249 3251 3253
    ## [151] 3255 3257 3259 3261 3263 3265 3267 3269 3271 3273 3275 3277 3279 3281 3283
    ## [166] 3285 3287 3289 3291 3293 3295 3297 3299 3301 3303 3305 3307 3309 3311 3313
    ## [181] 3315 3317 3319 3321 3323 3325 3327 3329 3331 3333 3335 3337 3339 3341 3343
    ## [196] 3345 3347 3349 3351 3353 3355 3357 3359 3361 3363 3365 3367 3369 3371 3373
    ## [211] 3375 3377 3379 3381 3383 3385 3387 3389 3391 3393 3395 3397 3399 3401 3403
    ## [226] 3405 3407 9890

``` r
combined_zillow = combined_zillow |> 
  mutate(county_zip = ifelse(county_zip != county_zillow, county_zillow, county_zip))
```

Merge again, relocate, and arrange to get new `combined_zillow` whose
number of rows (10677) equals to that of `zillow` datasets (10450).

``` r
combined_zillow = left_join(zillow, zip, by = "zip_code") |> 
    relocate(
    zip_code, county_zillow, neighborhood, # identification variables first
    year, month, day, # temporal variables
    zori, # measurement variables
    region_id_zillow, size_rank, county_zip, state_fips, county_code, county_fips # Others
  ) |> 
  arrange(zip_code, year, month, day)
```

### Dataset Description

The resulting tidy dataset contains 10450 observations and 13 variables.
Specifically,

- Total observations: 10450
- Unique ZIP codes: 149
- Unique neighborhoods: 43

The dataset combines rental price data from Zillow with geographic
information, tracking monthly ZORI (Zillow Observed Rent Index) values
from January 2015 to August 2024 across NYC zip codes.
